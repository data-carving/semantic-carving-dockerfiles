{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5037ee2f-8632-42ee-9a6d-1b7de7f0971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89104419-e7ea-46e5-af5e-f2ad6ff13039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(x):\n",
    "    print(f\"Processing: {x}\")\n",
    "    return f\"Processed {x}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04a3351-a1f3-4b03-8103-cfd43fa8557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask version: 2024.11.1\n",
      "Distributed version: 2024.11.1\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import distributed\n",
    "print(\"Dask version:\", dask.__version__)\n",
    "print(\"Distributed version:\", distributed.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ade494f-1a66-4a0a-bb01-b0a35597d7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b822186f0c074af2a41b355f8ba8798e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = coiled.Cluster(name=\"coiled-cluster\", container=\"tonhai/imerg-coiled-11.2024\", n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365310fa-d6fd-424c-9921-11d4d5133eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/stare/lib/python3.12/site-packages/distributed/client.py:1612: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+----------------+----------------+----------------+\n",
      "| Package | Client         | Scheduler      | Workers        |\n",
      "+---------+----------------+----------------+----------------+\n",
      "| python  | 3.12.7.final.0 | 3.12.2.final.0 | 3.12.2.final.0 |\n",
      "+---------+----------------+----------------+----------------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab5117a6-fce2-46bb-ae32-fc6e0f206f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed test_task\n"
     ]
    }
   ],
   "source": [
    "future_test = client.submit(test_function, \"test_task\")\n",
    "print(future_test.result())  # Should print \"Processed test_task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9f513b-7285-4a96-9ad2-1e3aad8f5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8203cf-852f-482a-94ac-faa1cd726a22",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e71f757-a597-468a-8c3e-bfec153548df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import os\n",
    "import typing\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Third-Party Imports\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import numpy.typing as npt\n",
    "import netCDF4\n",
    "import cc3d\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b95fdfb-4431-4068-896a-57de8de75ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# PUBLIC pf_search()\n",
    "# ------------------\n",
    "def pf_search(flist: list[str], dt_str: list[str], dyamond_mask_file: str, use_connectivity: int, dyamond_ccl_initial_file: str, dyamond_ccl_file: str, hidden_path: str, min_voxels: int, just_48: bool) -> None:\n",
    "\n",
    "    # Standard Imports\n",
    "    import os\n",
    "    import typing\n",
    "    from datetime import datetime\n",
    "    import pickle\n",
    "    import math\n",
    "    from multiprocessing import Pool\n",
    "    \n",
    "    # Third-Party Imports\n",
    "    import numpy as np\n",
    "    import numpy.ma as ma\n",
    "    import numpy.typing as npt\n",
    "    import netCDF4\n",
    "    import cc3d\n",
    "    from tqdm import tqdm\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib as mpl\n",
    "    import cartopy\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    import cycler\n",
    "\n",
    "    # List of Public objects from this module.\n",
    "    __all__ = ['pf_search']\n",
    "    \n",
    "    ##\n",
    "    # Markup Language Specification (see NumpyDoc Python Style Guide https://numpydoc.readthedocs.io/en/latest/format.html)\n",
    "    __docformat__ = \"Numpydoc\"\n",
    "    # ------------------------------------------------------------------------------\n",
    "    \n",
    "    ##\n",
    "    # Define Constants and State Variables\n",
    "    # ------------------------------------\n",
    "    def LON_TO_180(x): return ((x + 180.0) % 360.0) - 180.0\n",
    "    def LON_TO_360(x): return (x + 360.0) % 360.0\n",
    "    \n",
    "    ##\n",
    "    # Type Aliases\n",
    "    Optin: typing.TypeAlias = typing.Optional[typing.Union[bool, None]]\n",
    "\n",
    "    ###############################################################################\n",
    "    # PUBLIC basic_plot()\n",
    "    # -------------------\n",
    "    def basic_plot(map_this: npt.ArrayLike, lons: npt.ArrayLike, lats: npt.ArrayLike, the_time: str, pname: str) -> None:\n",
    "        \"\"\"Create a basic plot\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        map_this : npt.ArrayLike\n",
    "            _description_\n",
    "        lons : npt.ArrayLike\n",
    "            _description_\n",
    "        lats : npt.ArrayLike\n",
    "            _description_\n",
    "        the_time : str\n",
    "            _description_\n",
    "        pname : str\n",
    "            _description_\n",
    "        \"\"\"\n",
    "    \n",
    "        #  122 colors\n",
    "        all_colors = ['rosybrown', 'lightcoral', 'indianred', 'brown', 'firebrick', 'maroon', 'darkred', 'red',\n",
    "                      'salmon', 'tomato', 'darksalmon', 'coral', 'orangered', 'lightsalmon', 'sienna',\n",
    "                      'chocolate', 'saddlebrown', 'sandybrown', 'peachpuff', 'peru', 'linen', 'bisque',\n",
    "                      'darkorange', 'burlywood', 'tan', 'navajowhite', 'blanchedalmond', 'papayawhip', 'moccasin',\n",
    "                      'orange', 'wheat', 'oldlace', 'darkgoldenrod', 'goldenrod', 'cornsilk', 'gold', 'lemonchiffon',\n",
    "                      'khaki', 'palegoldenrod', 'darkkhaki', 'olive',\n",
    "                      'yellow', 'olivedrab', 'yellowgreen', 'darkolivegreen', 'greenyellow', 'chartreuse', 'lawngreen',\n",
    "                      'darkseagreen', 'palegreen', 'lightgreen', 'forestgreen', 'limegreen', 'darkgreen',\n",
    "                      'green', 'lime', 'seagreen', 'mediumseagreen', 'springgreen', 'mediumspringgreen',\n",
    "                      'mediumaquamarine', 'aquamarine', 'turquoise', 'lightseagreen', 'mediumturquoise', 'lightcyan',\n",
    "                      'paleturquoise', 'teal', 'darkcyan', 'aqua', 'cyan', 'darkturquoise',\n",
    "                      'cadetblue', 'powderblue', 'lightblue', 'deepskyblue', 'skyblue', 'lightskyblue', 'steelblue',\n",
    "                      'dodgerblue', 'lightsteelblue', 'cornflowerblue', 'royalblue', 'lavender', 'midnightblue', 'navy',\n",
    "                      'darkblue', 'mediumblue', 'blue', 'slateblue', 'darkslateblue', 'mediumslateblue', 'mediumpurple',\n",
    "                      'rebeccapurple', 'blueviolet', 'indigo', 'darkorchid', 'darkviolet', 'mediumorchid', 'thistle',\n",
    "                      'plum', 'violet', 'purple', 'darkmagenta', 'fuchsia', 'magenta', 'orchid', 'mediumvioletred',\n",
    "                      'deeppink', 'hotpink', 'lavenderblush', 'palevioletred', 'crimson', 'pink', 'lightpink']\n",
    "        ncolors = len(all_colors)\n",
    "    \n",
    "        # # mpl.rcParams['axes.color_cycle'] = all_colors\n",
    "        # n = 100\n",
    "        # color = pyplot.cm.viridis(np.linspace(0, 1,n))\n",
    "        # mpl.rcParams['axes.prop_cycle'] = cycler.cycler('color', color)\n",
    "    \n",
    "        # matplotlib.colors.ListedColormap\n",
    "        # cmap = plt.cm.tab20b                          # get a specific colormap\n",
    "        # cmaplist = cmap.colors                        # extract all colors\n",
    "        # mm = 20 # he number of colors in your base colormap.\n",
    "        # nn = 100\n",
    "    \n",
    "        # LinearSegmentedColormap\n",
    "        cmap = plt.cm.gist_rainbow\n",
    "        cmaplist = [mpl.colors.rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "        mm = 256\n",
    "        nn = 100\n",
    "        xx = math.ceil(nn / mm)\n",
    "        cmaplistext = cmaplist * xx  # repeat X times, here X = 5\n",
    "        customMap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplistext, nn)\n",
    "        # customMap = plt.cm.tab20b\n",
    "    \n",
    "        plot_dpi =  300\n",
    "        globe = ccrs.Globe(datum='WGS84', ellipse='WGS84')\n",
    "    \n",
    "        lon_0_global = 0\n",
    "        min_lat, max_lat = -90, 90\n",
    "        min_lon, max_lon = -180, 180\n",
    "    \n",
    "        map_extent = (min_lon, max_lon, min_lat, max_lat)\n",
    "        # print(map_extent)\n",
    "        geod_crs = ccrs.Geodetic(globe=globe)\n",
    "        flat_crs = ccrs.PlateCarree(central_longitude=0, globe=globe)\n",
    "        map_crs = ccrs.PlateCarree(central_longitude=lon_0_global, globe=globe)\n",
    "        if lon_0_global == 180:\n",
    "            data_crs = flat_crs\n",
    "        else:\n",
    "            data_crs = map_crs\n",
    "    \n",
    "        fig = plt.figure(figsize=(12, 4), frameon=True)\n",
    "        if pname.find(\"ccl\") != -1:\n",
    "            geo_axes = plt.axes(projection=map_crs, facecolor='k')\n",
    "        else:\n",
    "            geo_axes = plt.axes(projection=map_crs)\n",
    "    \n",
    "        # geo_axes.set_xlim(left=LON_TO_360(min_lon), right=LON_TO_360(max_lon))\n",
    "        # geo_axes.set_ylim(bottom=min_lat, top=max_lat)\n",
    "        if pname.find(\"ccl\") != -1:\n",
    "            geo_axes.add_feature(cfeature.COASTLINE, edgecolor='w', linewidth=0.25)\n",
    "        else:\n",
    "            geo_axes.add_feature(cfeature.COASTLINE)\n",
    "    \n",
    "        # geo_axes.contourf(lons, lats_nh, ma.masked_equal(map_this, 0), 1, transform=ccrs.PlateCarree())\n",
    "        i_ways = ['none', 'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16', 'spline36',\n",
    "                  'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel',\n",
    "                  'mitchell', 'sinc', 'lanczos', 'blackman']\n",
    "        iway = i_ways[1]\n",
    "        if pname.find(\"ccl\") != -1:\n",
    "            # param_dict = {\"extent\": map_extent, \"interpolation\": iway, \"cmap\": \"tab20\", \"origin\": 'upper'}\n",
    "            param_dict = {\"extent\": map_extent, \"interpolation\": iway, \"cmap\": customMap, \"origin\": 'lower'}\n",
    "        else:\n",
    "            param_dict = {\"extent\": map_extent, \"interpolation\": iway, \"cmap\": \"cool\", \"vmin\": 0, \"vmax\": 1, \"origin\": 'lower'}\n",
    "        geo_axes.imshow(ma.masked_equal(map_this, 0), transform=map_crs, **param_dict)\n",
    "    \n",
    "        now_ccl = sorted(np.unique(map_this[map_this > 0]).tolist())\n",
    "        n_ccl = len(now_ccl)\n",
    "        # print(f\"now_ccl  ({n_ccl:4d}): {now_ccl}\\n\\n\")\n",
    "        grid_lons, grid_lats = np.meshgrid(lons, lats)\n",
    "        grid_lons = grid_lons.flatten()\n",
    "        grid_lats = grid_lats.flatten()\n",
    "        for nl in now_ccl:\n",
    "            nl_mask = np.where(map_this == nl, 1, 0)\n",
    "            nl_mask = nl_mask.flatten()\n",
    "            nl_mask_hits = np.nonzero(nl_mask)[0]\n",
    "            now_labs_grids = nl_mask_hits.tolist()\n",
    "            nl_lons = grid_lons[now_labs_grids]\n",
    "            nl_lats = grid_lats[now_labs_grids]\n",
    "            nl_mean_lon = np.mean(nl_lons)\n",
    "            nl_mean_lat = np.mean(nl_lats)\n",
    "            geo_axes.text(nl_mean_lon, nl_mean_lat, f\"{nl}\", color='w', fontsize=3, weight='bold', horizontalalignment='center', transform=geod_crs)\n",
    "    \n",
    "        # mikemike\n",
    "        # os._exit(0)\n",
    "    \n",
    "        tcolor = \"w\" if pname.find(\"ccl\") != -1 else \"k\"\n",
    "        geo_axes.text(0, 80, the_time, color=tcolor, fontsize=10, weight='bold', horizontalalignment='center', transform=geod_crs)\n",
    "    \n",
    "        fig.savefig(pname, dpi=plot_dpi, facecolor='w', edgecolor='w',\n",
    "                    orientation='landscape', bbox_inches='tight', pad_inches=0.02)\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "    \n",
    "        return\n",
    "    ###############################################################################\n",
    "    \n",
    "    ###############################################################################\n",
    "    # PUBLIC edge_check()\n",
    "    # -------------------\n",
    "    def edge_check(lmap) -> tuple[npt.ArrayLike, int]:\n",
    "        \"\"\"Check if ccl labels at end of map edges line up in latitude.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        lmap : ndarray\n",
    "            Result of applying cc3d.connected_components()\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray\n",
    "            lmap possibly remapped.\n",
    "        int\n",
    "            Flag for if lmap remapped.\n",
    "        \"\"\"\n",
    "        verbose = 0\n",
    "        ##\n",
    "        # Start map edge (-180 deg),  ndarray dtype=uint32)\n",
    "        edge_0_labs = lmap[:, 0]\n",
    "        # Note this will include CCL that cross and don't cross the map edge.\n",
    "        is_edge_0 = np.unique(edge_0_labs[edge_0_labs > 0]).tolist()\n",
    "        # if verbose:\n",
    "        #     print(f\"\\tedge_check():\\n\\t\\t{is_edge_0 = }\")\n",
    "    \n",
    "        ##\n",
    "        # End map edge (+180 deg)\n",
    "        edge_1_labs = lmap[:, -1]\n",
    "        is_edge_1 = np.unique(edge_1_labs[edge_1_labs > 0]).tolist()\n",
    "        # if verbose:\n",
    "        #     print(f\"\\tedge_check():\\n\\t\\t{is_edge_1 = }\")\n",
    "    \n",
    "        ##\n",
    "        # Check if labels at both map edges line up in latitude.\n",
    "        #   Assume features travel westerly (from West -> East or wrap from is_edge_1 -> is_edge_0)\n",
    "        remapped_ccl = {}\n",
    "        if is_edge_0 and is_edge_1:\n",
    "            # if verbose:\n",
    "            #     print(f\"\\n\\t{'Idx':<4s} {'Edge0':<5s} {'Edge1':<5s}\")\n",
    "            #     for lidx in range(len(edge_1_labs)):\n",
    "            #         if edge_0_labs[lidx] == 0 or edge_1_labs[lidx] == 0:\n",
    "            #             continue\n",
    "            #         print(f\"\\t{lidx:04d} {int(edge_0_labs[lidx]):5d} {int(edge_1_labs[lidx]):5d}\")\n",
    "    \n",
    "            nlat = lmap.shape[0]\n",
    "    \n",
    "            # # Debug RAW\n",
    "            # for jjidx in range(nlat):\n",
    "            #     print(f\"\\t{jjidx:04d} {int(lmap[jjidx, -2]):4d} {int(lmap[jjidx, -1]):4d} | {int(lmap[jjidx, 0]):4d} {int(lmap[jjidx, 1]):4d}\")\n",
    "            # os._exit(1)\n",
    "    \n",
    "            # # Debug Focus\n",
    "            # target_jidx = 1554\n",
    "            # # print(\"\\n\\n\")\n",
    "            # # for jjidx in range(target_jidx - 1, target_jidx + 2, 1):\n",
    "            # #     print(f\"\\t{jjidx:04d} {int(lmap[jjidx, -2]):4d} {int(lmap[jjidx, -1]):4d} | {int(lmap[jjidx, 0]):4d} {int(lmap[jjidx, 1]):4d}\")\n",
    "            # # print(\"\\n\\n\")\n",
    "            # # print()\n",
    "            # # os._exit(1)\n",
    "    \n",
    "            for jidx in range(nlat):\n",
    "                # print(f\"Checking {jidx:04d}: {int(lmap[jidx, -2]):4d} {int(lmap[jidx, -1]):4d} | {int(lmap[jidx, 0]):4d} {int(lmap[jidx, 1]):4d}\")\n",
    "                ##\n",
    "                # Guard against holes:\n",
    "                \"\"\"\n",
    "                N/S Order\n",
    "                    0         SP\n",
    "                              .\n",
    "                              .\n",
    "                              .\n",
    "                    nlat -1   NP\n",
    "    \n",
    "                E/W Order\n",
    "                    Edge_0                        Edge_1\n",
    "                    0       1   ...   nlon - 2    nlon - 1\n",
    "    \n",
    "                Moore Neighborhood around point 0\n",
    "                    1   2   3           1   2   3   jidx - 1\n",
    "                    8   0   4           8   0   4   jidx\n",
    "                    7   6   5           7   6   5   jidx + 1\n",
    "                                  iidx -1   0  +1\n",
    "    \n",
    "                Moore Neighborhood along Edge_0 not in a polar row\n",
    "                    edge_0_moore = [2, 4, 6]\n",
    "                        here iidx == 0 means x index 0, '-' unused indices, '*' is index being tested\n",
    "                                -  | 2   -   jidx - 1\n",
    "                                -  | *   4   jidx\n",
    "                                -  | 6   -   jidx + 1\n",
    "                        iidx   -1  | 0  +1\n",
    "                                   ^\n",
    "                                   map edge\n",
    "    \n",
    "                Moore Neighborhood along Edge_1 not in a polar row\n",
    "                    edge_1_moore = [2, 6, 8]\n",
    "                        here iidx == -1 means x index nlon - 1, '-' unused indices, '*' is index being tested\n",
    "                                -  2 |  -   jidx - 1\n",
    "                                8  * |  -   jidx\n",
    "                                -  6 |  -   jidx + 1\n",
    "                        iidx   -1  0 | +1\n",
    "                                     ^\n",
    "                                     map edge\n",
    "    \n",
    "                Moore Neighborhood at SPole\n",
    "                    edge_0_moore = [4, 6]\n",
    "                                -  | *   4   jidx\n",
    "                                -  | 6   -   jidx + 1\n",
    "                        iidx   -1  | 0  +1\n",
    "                                   ^\n",
    "                                   map edge\n",
    "    \n",
    "                    edge_1_moore = [6, 8]\n",
    "                                8  * |  -   jidx\n",
    "                                -  6 |  -   jidx + 1\n",
    "                        iidx   -1  0 | +1\n",
    "                                     ^\n",
    "                                     map edge\n",
    "    \n",
    "                Moore Neighborhood at NPole\n",
    "                    edge_0_moore = [2, 4]\n",
    "                                -  | 2   -   jidx - 1\n",
    "                                -  | *   4   jidx\n",
    "                        iidx   -1  | 0  +1\n",
    "                                   ^\n",
    "                                   map edge\n",
    "    \n",
    "                    edge_1_moore = [2, 6]\n",
    "                                -  2 |  -   jidx - 1\n",
    "                                8  * |  -   jidx\n",
    "                        iidx   -1  0 | +1\n",
    "                                     ^\n",
    "                                     map edge\n",
    "    \n",
    "                Here a 'hole' appears as a zero (no CCL label along a edge that has a neighbor that is labeled around it)\n",
    "    \n",
    "                    A hole along Edge_0, here the CCL 46 has a hole at index 0 which without care might interfere with merging CCLs 46 and 44\n",
    "                           44 | 46  46   jidx - 1\n",
    "                           44 | 0   46   jidx\n",
    "                           44 | 46  46   jidx + 1\n",
    "                      iidx -1 | 0   +1\n",
    "                              ^\n",
    "                              map edge\n",
    "    \n",
    "                    A hole along Edge_1, here the CCL 46 has a hole at index 0 which without care might interfere with merging CCLs 46 and 44\n",
    "                           44  46 | 46   jidx - 1\n",
    "                           44  0  | 46   jidx\n",
    "                           44  46 | 46   jidx + 1\n",
    "                     iidx  -1  0  | +1\n",
    "                                  ^\n",
    "                                  map edge\n",
    "                \"\"\"\n",
    "                if jidx in [0, nlat - 1]:\n",
    "                    # Polar row\n",
    "                    if jidx == 0:\n",
    "                        # At SPole\n",
    "                        edge_0_moore = [lmap[jidx, 1], lmap[jidx + 1, 0]]\n",
    "                        edge_1_moore = [lmap[jidx, -2], lmap[jidx + 1, -1]]\n",
    "                    else:\n",
    "                        # At NPole\n",
    "                        edge_0_moore = [lmap[jidx - 1, 0], lmap[jidx, 1]]\n",
    "                        edge_1_moore = [lmap[jidx - 1, -1], lmap[jidx, -2]]\n",
    "                else:\n",
    "                    edge_0_moore = [lmap[jidx - 1, 0], lmap[jidx, 1], lmap[jidx + 1, 0]]\n",
    "                    # 3 rows around edge_1 and jidx\n",
    "                    edge_1_moore = [lmap[jidx - 1, -1], lmap[jidx, -2], lmap[jidx + 1, -1]]\n",
    "    \n",
    "                # # Debug Edge\n",
    "                # if jidx == target_jidx:\n",
    "                #     print(\"\\n\\n\")\n",
    "                #     for jjidx in range(target_jidx - 1, target_jidx + 2, 1):\n",
    "                #         print(f\"\\t{jjidx:04d} {int(lmap[jjidx, -2]):4d} {int(lmap[jjidx, -1]):4d} | {int(lmap[jjidx, 0]):4d} {int(lmap[jjidx, 1]):4d}\")\n",
    "                #     print(\"\\n\\n\")\n",
    "                #     print(f\"{jidx:05d} {edge_0_moore = }\\t{edge_0_labs[jidx] = }\")\n",
    "                #     print(f\"{jidx:05d} {edge_1_moore = }\\t{edge_1_labs[jidx] = }\")\n",
    "                #     os._exit(1)\n",
    "                # # if jidx < target_jidx:\n",
    "                # #     continue\n",
    "    \n",
    "                ##\n",
    "                # Fill holes\n",
    "                # print(f\"{jidx:05d} {edge_0_moore = }\\t{edge_0_labs[jidx] = }\")\n",
    "                if edge_0_labs[jidx] == 0 and len([_ for _ in edge_0_moore if _ != 0]) == 3:\n",
    "                    # Possible hole, find the largest neighboring CCL label in edge_0_moore and apply to edge_0_labs[jidx]\n",
    "                    edge_0_labs[jidx] = max(edge_0_moore)\n",
    "                # print(f\"{jidx:05d} {edge_1_moore = }\\t{edge_1_labs[jidx] = }\")\n",
    "                if edge_1_labs[jidx] == 0 and len([_ for _ in edge_1_moore if _ != 0]) == 3:\n",
    "                    # Possible hole, find the largest CCL label in edge_1_moore and apply to edge_1_labs[jidx]\n",
    "                    edge_1_labs[jidx] = max(edge_1_moore)\n",
    "    \n",
    "                # # Debug Fill\n",
    "                # if jidx == target_jidx:\n",
    "                #     print(f\"{jidx:05d} {edge_0_labs[jidx] = }\")\n",
    "                #     print(f\"{jidx:05d} {edge_1_labs[jidx] = }\")\n",
    "                #     for ridx, rval in remapped_ccl.items():\n",
    "                #         print(f\"{ridx:4d}: {rval}\")\n",
    "                #     os._exit(1)\n",
    "                # continue\n",
    "                # if jidx < target_jidx:\n",
    "                #     continue\n",
    "    \n",
    "                if edge_0_labs[jidx] > 0 and edge_1_labs[jidx] > 0:\n",
    "                    # CCL at same lat on both map edges\n",
    "                    # print(f\"{jidx:05d} {edge_0_labs[jidx] = }\\t{edge_1_labs[jidx] = }\")\n",
    "                    if edge_1_labs[jidx] not in remapped_ccl:\n",
    "                        # This CCL hasn't been remapped, so in in is_edge_1\n",
    "                        if edge_0_labs[jidx] != edge_1_labs[jidx]:\n",
    "                            # Remap CCL to is_edge_0 side\n",
    "                            remapped_ccl[int(edge_1_labs[jidx])] = int(edge_0_labs[jidx])\n",
    "                            if verbose:\n",
    "                                print(f\"\\tRemapped {edge_1_labs[jidx]:4d} -> {edge_0_labs[jidx]:4d}\")\n",
    "                            # Replace all instances of remapped_ccl\n",
    "                            lmap = np.where(lmap == int(edge_1_labs[jidx]), int(edge_0_labs[jidx]), lmap)\n",
    "                            # if jidx == target_jidx:\n",
    "                            #     print(\"\\n\\n\")\n",
    "                            #     for jjidx in range(target_jidx - 1, target_jidx + 2, 1):\n",
    "                            #         print(f\"\\t{jjidx:04d} {int(lmap[jjidx, -2]):4d} {int(lmap[jjidx, -1]):4d} | {int(lmap[jjidx, 0]):4d} {int(lmap[jjidx, 1]):4d}\")\n",
    "                            #     print(\"\\n\\n\")\n",
    "                            #     os._exit(1)\n",
    "                # # Debug\n",
    "                # if jidx == target_jidx:\n",
    "                #     os._exit(1)\n",
    "    \n",
    "                # Done lat loop\n",
    "        return lmap, 1 if remapped_ccl else 0\n",
    "    ###############################################################################\n",
    "    ###############################################################################\n",
    "    # PUBLIC basic_plot_pool()\n",
    "    # ------------------------\n",
    "    def basic_plot_pool(map_this: str, lons: npt.ArrayLike, lats: npt.ArrayLike, the_time: str, pname: str) -> str:\n",
    "        \"\"\"Create a basic plot\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        map_this : npt.ArrayLike\n",
    "            _description_\n",
    "        lons : npt.ArrayLike\n",
    "            _description_\n",
    "        lats : npt.ArrayLike\n",
    "            _description_\n",
    "        the_time : str\n",
    "            _description_\n",
    "        pname : str\n",
    "            _description_\n",
    "        \"\"\"\n",
    "    \n",
    "        ccl_map = np.load(map_this)\n",
    "    \n",
    "        #  122 colors\n",
    "        all_colors = ['rosybrown', 'lightcoral', 'indianred', 'brown', 'firebrick', 'maroon', 'darkred', 'red',\n",
    "                      'salmon', 'tomato', 'darksalmon', 'coral', 'orangered', 'lightsalmon', 'sienna',\n",
    "                      'chocolate', 'saddlebrown', 'sandybrown', 'peachpuff', 'peru', 'linen', 'bisque',\n",
    "                      'darkorange', 'burlywood', 'tan', 'navajowhite', 'blanchedalmond', 'papayawhip', 'moccasin',\n",
    "                      'orange', 'wheat', 'oldlace', 'darkgoldenrod', 'goldenrod', 'cornsilk', 'gold', 'lemonchiffon',\n",
    "                      'khaki', 'palegoldenrod', 'darkkhaki', 'olive',\n",
    "                      'yellow', 'olivedrab', 'yellowgreen', 'darkolivegreen', 'greenyellow', 'chartreuse', 'lawngreen',\n",
    "                      'darkseagreen', 'palegreen', 'lightgreen', 'forestgreen', 'limegreen', 'darkgreen',\n",
    "                      'green', 'lime', 'seagreen', 'mediumseagreen', 'springgreen', 'mediumspringgreen',\n",
    "                      'mediumaquamarine', 'aquamarine', 'turquoise', 'lightseagreen', 'mediumturquoise', 'lightcyan',\n",
    "                      'paleturquoise', 'teal', 'darkcyan', 'aqua', 'cyan', 'darkturquoise',\n",
    "                      'cadetblue', 'powderblue', 'lightblue', 'deepskyblue', 'skyblue', 'lightskyblue', 'steelblue',\n",
    "                      'dodgerblue', 'lightsteelblue', 'cornflowerblue', 'royalblue', 'lavender', 'midnightblue', 'navy',\n",
    "                      'darkblue', 'mediumblue', 'blue', 'slateblue', 'darkslateblue', 'mediumslateblue', 'mediumpurple',\n",
    "                      'rebeccapurple', 'blueviolet', 'indigo', 'darkorchid', 'darkviolet', 'mediumorchid', 'thistle',\n",
    "                      'plum', 'violet', 'purple', 'darkmagenta', 'fuchsia', 'magenta', 'orchid', 'mediumvioletred',\n",
    "                      'deeppink', 'hotpink', 'lavenderblush', 'palevioletred', 'crimson', 'pink', 'lightpink']\n",
    "        ncolors = len(all_colors)\n",
    "    \n",
    "        # # mpl.rcParams['axes.color_cycle'] = all_colors\n",
    "        # n = 100\n",
    "        # color = pyplot.cm.viridis(np.linspace(0, 1,n))\n",
    "        # mpl.rcParams['axes.prop_cycle'] = cycler.cycler('color', color)\n",
    "    \n",
    "        # matplotlib.colors.ListedColormap\n",
    "        # cmap = plt.cm.tab20b                          # get a specific colormap\n",
    "        # cmaplist = cmap.colors                        # extract all colors\n",
    "        # mm = 20 # he number of colors in your base colormap.\n",
    "        # nn = 100\n",
    "    \n",
    "        # LinearSegmentedColormap\n",
    "        cmap = plt.cm.gist_rainbow\n",
    "        cmaplist = [mpl.colors.rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "        mm = 256\n",
    "        nn = 100\n",
    "        xx = math.ceil(nn / mm)\n",
    "        cmaplistext = cmaplist * xx  # repeat X times, here X = 5\n",
    "        customMap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplistext, nn)\n",
    "        # customMap = plt.cm.tab20b\n",
    "    \n",
    "        plot_dpi =  300\n",
    "        globe = ccrs.Globe(datum='WGS84', ellipse='WGS84')\n",
    "    \n",
    "        lon_0_global = 0\n",
    "        min_lat, max_lat = -90, 90\n",
    "        min_lon, max_lon = -180, 180\n",
    "    \n",
    "        map_extent = (min_lon, max_lon, min_lat, max_lat)\n",
    "        # print(map_extent)\n",
    "        geod_crs = ccrs.Geodetic(globe=globe)\n",
    "        flat_crs = ccrs.PlateCarree(central_longitude=0, globe=globe)\n",
    "        map_crs = ccrs.PlateCarree(central_longitude=lon_0_global, globe=globe)\n",
    "        if lon_0_global == 180:\n",
    "            data_crs = flat_crs\n",
    "        else:\n",
    "            data_crs = map_crs\n",
    "    \n",
    "        fig = plt.figure(figsize=(12, 4), frameon=True)\n",
    "        if pname.find(\"ccl\") != -1:\n",
    "            geo_axes = plt.axes(projection=map_crs, facecolor='k')\n",
    "        else:\n",
    "            geo_axes = plt.axes(projection=map_crs)\n",
    "    \n",
    "        # geo_axes.set_xlim(left=LON_TO_360(min_lon), right=LON_TO_360(max_lon))\n",
    "        # geo_axes.set_ylim(bottom=min_lat, top=max_lat)\n",
    "        if pname.find(\"ccl\") != -1:\n",
    "            geo_axes.add_feature(cfeature.COASTLINE, edgecolor='w', linewidth=0.25)\n",
    "        else:\n",
    "            geo_axes.add_feature(cfeature.COASTLINE)\n",
    "    \n",
    "        # geo_axes.contourf(lons, lats_nh, ma.masked_equal(map_this, 0), 1, transform=ccrs.PlateCarree())\n",
    "        i_ways = ['none', 'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16', 'spline36',\n",
    "                  'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel',\n",
    "                  'mitchell', 'sinc', 'lanczos', 'blackman']\n",
    "        iway = i_ways[1]\n",
    "        if pname.find(\"ccl\") != -1:\n",
    "            # param_dict = {\"extent\": map_extent, \"interpolation\": iway, \"cmap\": \"tab20\", \"origin\": 'upper'}\n",
    "            param_dict = {\"extent\": map_extent, \"interpolation\": iway, \"cmap\": customMap, \"origin\": 'lower'}\n",
    "        else:\n",
    "            param_dict = {\"extent\": map_extent, \"interpolation\": iway, \"cmap\": \"cool\", \"vmin\": 0, \"vmax\": 1, \"origin\": 'lower'}\n",
    "        geo_axes.imshow(ma.masked_equal(ccl_map, 0), transform=map_crs, **param_dict)\n",
    "    \n",
    "        \n",
    "        tcolor = \"w\" if pname.find(\"ccl\") != -1 else \"k\"\n",
    "        geo_axes.text(0, 80, the_time, color=tcolor, fontsize=10, weight='bold', horizontalalignment='center', transform=geod_crs)\n",
    "    \n",
    "        fig.savefig(pname, dpi=plot_dpi, facecolor='w', edgecolor='w',\n",
    "                    orientation='landscape', bbox_inches='tight', pad_inches=0.02)\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "    \n",
    "        return pname\n",
    "    ###############################################################################\n",
    "    ###############################################################################\n",
    "    # PUBLIC get_ccl()\n",
    "    # ----------------\n",
    "    def get_ccl(tidx: int, now_mask: npt.ArrayLike, min_voxels: int, use_connectivity: int, sname: str) -> str:\n",
    "        print(f\"\\tDoing {tidx:4d} ... \", end='')\n",
    "        ##\n",
    "        # Find current 2D CCL\n",
    "        ccl_map = cc3d.connected_components(now_mask, delta=0, connectivity=use_connectivity, return_N=False)\n",
    "        ##\n",
    "        # Mask if voxel count is too low\n",
    "        now_ccl = sorted(np.unique(ccl_map[ccl_map > 0]).tolist())\n",
    "        for clab in now_ccl:\n",
    "            ##\n",
    "            # Mask where clab located\n",
    "            cl_mask = np.where(ccl_map == clab, 1, 0)\n",
    "            cl_voxels = int(np.count_nonzero(cl_mask))\n",
    "            if cl_voxels < min_voxels:\n",
    "                # Drop CCL label\n",
    "                ccl_map = np.where(ccl_map == clab, 0, ccl_map)\n",
    "        ##\n",
    "        # Edge Check of current CCL\n",
    "        ccl_map, map_replace = edge_check(ccl_map)\n",
    "    \n",
    "        # Save to File\n",
    "        np.save(sname, ccl_map)\n",
    "        print(\" Done\")\n",
    "    \n",
    "        return sname\n",
    "    ###############################################################################\n",
    "    ###############################################################################\n",
    "    # PUBLIC track_labels()\n",
    "    # ---------------------\n",
    "    def track_labels(lmap_prev, lmap, live_ccl, dead_ccl, hemi_sep: tuple[int, int]) -> tuple[npt.ArrayLike, list[int], list[int], list[str]]:\n",
    "        \"\"\"Track CCL (Time Connect)\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        lmap_prev : ndarray\n",
    "            CCL from previous time-step\n",
    "        lmap : ndarray\n",
    "            CCL from current time-step\n",
    "        live_ccl : list\n",
    "            List of active CCL\n",
    "        dead_ccl : _type_\n",
    "            List of inactive CCL\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        npt.ArrayLike\n",
    "            Updated version of lmap\n",
    "        list[int]\n",
    "            Updated list of active CCL\n",
    "        list[int]\n",
    "            Updated list of inactive CCL\n",
    "        \"\"\"\n",
    "        local_verbose = [False, True][0]\n",
    "        local_verboser = [False, True][0]\n",
    "        mega_msg = []\n",
    "        if local_verbose:\n",
    "            mega_msg.append(\"\\tIn track_labels()\")\n",
    "        \"\"\"\n",
    "        Link (time connect or track) two fields of integer CCL labels\n",
    "            lmap_prev : CCL from previous time-step\n",
    "            lmap      : CCL from current time-step\n",
    "    \n",
    "            last_labs : list of unique CCL labels in lmap_prev\n",
    "            now_labs  : list of unique CCL labels in lmap\n",
    "    \n",
    "            Issues to deal with:\n",
    "                1) last_labs should be some sort of contiguous list of numbers from 1 to len(last_labs)-1\n",
    "                2) now_labs should be some sort of contiguous list of numbers from 1 to len(now_labs)-1\n",
    "                Thus, the CCL labels in last_labs have not relationship to those in now_labs but they can/will have similar/same values.\n",
    "                To reduce this an offset of 5000 is applied to lmap and now_labs to keep them clearly separated.\n",
    "                No offset is applied to last_labs as these labels include those held in live_ccl and dead_ccl.\n",
    "        \"\"\"\n",
    "        ##\n",
    "        # Set of CCL from previous time-step (not whole record!)\n",
    "        last_labs = sorted(np.unique(lmap_prev[lmap_prev > 0]).tolist())\n",
    "        last_labs_set = set(last_labs)\n",
    "        if local_verbose:\n",
    "            mega_msg.append(f\"\\t\\tlast_labs ({len(last_labs)}): {last_labs}\")\n",
    "    \n",
    "        ##\n",
    "        # Set of current CCL, add offset so clear renaming\n",
    "        lmap = np.where(lmap > 0, lmap + 5000, lmap)\n",
    "        now_labs = sorted(np.unique(lmap[lmap > 0]).tolist())\n",
    "        now_labs_set = set(now_labs)\n",
    "        if local_verbose:\n",
    "            mega_msg.append(f\"\\t\\tnow_labs ({len(now_labs)}): {now_labs}\")\n",
    "            mega_msg.append(\"\\t\\tMapping now_labs to last_labs\")\n",
    "        # print('\\n'.join(mega_msg)); return [], [], []\n",
    "    \n",
    "        \"\"\"\n",
    "        The first step loops over each member of now_labs (nl) and checks if that labels spatial grids directly correspond to the spatial grids of a member of last_labs (ll).\n",
    "        If there is an overlap, we can assume that the now_labs label connects in time to the last_labs label.\n",
    "    \n",
    "            An entry is then made to the dictionary, if nl hasn't already been added to direct_overlap (see Issues below) a tuple is added\n",
    "                direct_overlap[nl] = (ll, overlap_size)\n",
    "            if nl is already in direct_overlap (i.e., nl overlaps with multiple members of last_labs), a list is created.\n",
    "                direct_overlap[nl] = [(previous entries), ... (ll, overlap_size)]\n",
    "            Issues to deal with:\n",
    "                1) It is possible for the spatial grids of a last_labs label overlap with multiple spatial grids of now_labs labels.\n",
    "    \n",
    "        If no overlaps, no entry is made in direct_overlap, but nl does represent a newly started track.\n",
    "    \n",
    "        Example:\n",
    "    \n",
    "            Checking Now Lab        5001: nl_locs (7620)\n",
    "                Checking Previous Lab      1: nl_locs (7620)        <= Simple overlap, entry in direct_overlap 5001: (1, 6785)\n",
    "                    Overlaps 6785\n",
    "    \n",
    "            ...\n",
    "    \n",
    "            Checking Now Lab        5008: nl_locs (1843)            <= Multiple overlaps, entry in direct_overlap 5008: [(11, 921), (19, 517)]\n",
    "                Checking Previous Lab     11: nl_locs (1309)\n",
    "                    Overlaps 921\n",
    "                Checking Previous Lab     19: nl_locs (645)\n",
    "                    Overlaps 517\n",
    "    \n",
    "            ...\n",
    "    \n",
    "            Checking Now Lab        5033: nl_locs (834)             <= No overlaps, new track, no entry in direct_overlap\n",
    "    \n",
    "        Speed ups\n",
    "            Find now_labs and last_labs that are fully in NH or SH to limit searching.\n",
    "            Likewise for E/W Hemisphere?\n",
    "    \n",
    "        \"\"\"\n",
    "        direct_overlap = {}\n",
    "    \n",
    "        ##\n",
    "        # Find CCL that are wholly in one hemisphere or the other (speed up overlap checks)\n",
    "        #   106 now_labs: 44 in NH, 54 in SH, and 8 span\n",
    "        #   118 last_labs: 56 in NH, 54 in SH, and 8 span\n",
    "        now_labs_nh = []\n",
    "        now_labs_sh = []\n",
    "        now_labs_grids = {}\n",
    "        for nl in now_labs:\n",
    "            ##\n",
    "            # Check each current CCL\n",
    "            nl_mask = np.where(lmap == nl, 1, 0)\n",
    "            nl_mask = nl_mask.flatten()\n",
    "            nl_mask_hits = np.nonzero(nl_mask)[0]\n",
    "            now_labs_grids[nl] = set(nl_mask_hits.tolist())\n",
    "            ##\n",
    "            # CCL wholly in NH\n",
    "            in_nh = True if np.amin(nl_mask_hits) >= hemi_sep[1] else False\n",
    "            if in_nh:\n",
    "                in_sh = False\n",
    "                now_labs_nh.append(nl)\n",
    "            else:\n",
    "                ##\n",
    "                # CCL wholly in SH\n",
    "                in_sh = True if np.amax(nl_mask_hits) <= hemi_sep[0] else False\n",
    "                if in_sh:\n",
    "                    now_labs_sh.append(nl)\n",
    "        # for nl in now_labs_grids.keys():\n",
    "        #     print(f\"{nl:5d}: {len(now_labs_grids[nl])}\")\n",
    "    \n",
    "        if local_verbose:\n",
    "            tmp_ = len(now_labs_nh) + len(now_labs_sh)\n",
    "            tmp__ = len(now_labs)\n",
    "            mega_msg.append(f\"\\t\\t{tmp__} now_labs: {len(now_labs_nh)} in NH, {len(now_labs_sh)} in SH, and {tmp__ - tmp_} span\")\n",
    "        last_labs_nh = []\n",
    "        last_labs_sh = []\n",
    "        last_labs_grids = {}\n",
    "        for nl in last_labs:\n",
    "            ##\n",
    "            # Check each current CCL\n",
    "            nl_mask = np.where(lmap_prev == nl, 1, 0)\n",
    "            nl_mask = nl_mask.flatten()\n",
    "            nl_mask_hits = np.nonzero(nl_mask)[0]\n",
    "            last_labs_grids[nl] = set(nl_mask_hits.tolist())\n",
    "            ##\n",
    "            # CCL wholly in NH\n",
    "            in_nh = True if np.amin(nl_mask_hits) >= hemi_sep[1] else False\n",
    "            if in_nh:\n",
    "                in_sh = False\n",
    "                last_labs_nh.append(nl)\n",
    "            else:\n",
    "                ##\n",
    "                # CCL wholly in SH\n",
    "                in_sh = True if np.amax(nl_mask_hits) <= hemi_sep[0] else False\n",
    "                if in_sh:\n",
    "                    last_labs_sh.append(nl)\n",
    "        if local_verbose:\n",
    "            tmp_ = len(last_labs_nh) + len(last_labs_sh)\n",
    "            tmp__ = len(last_labs)\n",
    "            mega_msg.append(f\"\\t\\t{tmp__} last_labs: {len(last_labs_nh)} in NH, {len(last_labs_sh)} in SH, and {tmp__ - tmp_} span\")\n",
    "        # for nl in last_labs_grids.keys():\n",
    "        #     print(f\"{nl:5d}: {len(last_labs_grids[nl])}\")\n",
    "    \n",
    "        now_labs_nh = set(now_labs_nh)\n",
    "        now_labs_sh = set(now_labs_sh)\n",
    "        last_labs_nh = set(last_labs_nh)\n",
    "        last_labs_sh = set(last_labs_sh)\n",
    "        for nl in now_labs:\n",
    "            ##\n",
    "            # Check each current CCL\n",
    "            # nl_locs = np.where(lmap == nl)\n",
    "            # if local_verboser:\n",
    "            #     mega_msg.append(f\"\\t\\tChecking Now Lab\\t\\t{nl:4d}: nl_locs ({len(nl_locs[0])})\")\n",
    "    \n",
    "            # nl_mask = np.where(lmap == nl, 1, 0)\n",
    "            # nl_mask = nl_mask.flatten()\n",
    "            # nl_mask_hits = np.nonzero(nl_mask)[0]\n",
    "            nl_mask_hits = now_labs_grids[nl]\n",
    "    \n",
    "            now_just_nh = True if nl in now_labs_nh else False\n",
    "            now_just_sh = True if nl in now_labs_sh else False\n",
    "    \n",
    "            if local_verboser:\n",
    "                mega_msg.append(f\"\\t\\tChecking Now Lab\\t\\t{nl:4d}: nl_locs ({len(nl_mask_hits)}) {now_just_nh = } {now_just_sh = }\")\n",
    "            for ll in last_labs:\n",
    "                last_just_nh = True if nl in last_labs_nh else False\n",
    "                last_just_sh = True if nl in last_labs_sh else False\n",
    "                if now_just_nh and last_just_sh:\n",
    "                    continue\n",
    "                if now_just_sh and last_just_nh:\n",
    "                    continue\n",
    "                ##\n",
    "                # Check each previous time-step CCL for overlap\n",
    "                # ll_mask = np.where(lmap_prev == ll, 1, 0)\n",
    "                # ll_mask = ll_mask.flatten()\n",
    "                # ll_mask_hits = np.nonzero(ll_mask)[0]\n",
    "                ll_mask_hits = last_labs_grids[ll]\n",
    "                # if local_verboser:\n",
    "                #     mega_msg.append(f\"\\t\\t\\tChecking Previous Lab   {ll:4d}: nl_locs ({len(ll_mask_hits)})\")\n",
    "    \n",
    "                # overlap = np.intersect1d(nl_mask_hits, ll_mask_hits)\n",
    "                overlap = nl_mask_hits.intersection(ll_mask_hits)\n",
    "                overlap_size = len(overlap)\n",
    "                if overlap_size:\n",
    "                    if local_verboser:\n",
    "                        mega_msg.append(f\"\\t\\t\\t\\tOverlaps {overlap_size}\")\n",
    "                    if nl in direct_overlap:\n",
    "                        # Extend existing overlapping CCL entry\n",
    "                        old = direct_overlap[nl]\n",
    "                        if isinstance(old, tuple):\n",
    "                            new = [old, (ll, overlap_size)]\n",
    "                        else:\n",
    "                            new.append((ll, overlap_size))\n",
    "                        direct_overlap[nl] = new\n",
    "                    else:\n",
    "                        # Create new overlapping CCL entry\n",
    "                        direct_overlap[nl] = (ll, overlap_size)\n",
    "                # break\n",
    "            # break\n",
    "        if local_verbose:\n",
    "            mega_msg.append(f\"\\t\\t{direct_overlap = }\")\n",
    "        # print('\\n'.join(mega_msg))\n",
    "        # os._exit(1)\n",
    "        # print('\\n'.join(mega_msg)); return [], [], []\n",
    "    \n",
    "        # # local_verboser =  True\n",
    "        # direct_overlap = {5001: (1, 6785), 5002: (2, 1492), 5003: (5, 700), 5004: (5, 6430), 5005: (7, 684),\n",
    "        #                   5006: (8, 5725), 5007: (3, 765), 5008: [(11, 921), (19, 517)], 5009: (9, 4161),\n",
    "        #                   5010: (10, 2229), 5011: (12, 3242), 5012: (14, 471), 5013: (9, 2710), 5014: (13, 3277),\n",
    "        #                   5015: (15, 1649), 5016: (9, 7047), 5017: [(16, 14283), (24, 682)], 5018: (17, 8777),\n",
    "        #                   5019: (18, 907), 5020: (20, 327), 5021: (21, 959), 5022: (22, 14030), 5023: (23, 2916),\n",
    "        #                   5024: (18, 510), 5025: (26, 782), 5026: (25, 1718), 5027: (27, 470), 5028: (28, 448),\n",
    "        #                   5029: (16, 827), 5030: (29, 702), 5031: (30, 1325), 5032: (31, 2615), 5034: (32, 938),\n",
    "        #                   5035: (33, 1221), 5037: (34, 818), 5038: (37, 869), 5039: (36, 1191), 5041: (40, 39563),\n",
    "        #                   5042: (41, 797), 5043: (43, 8330), 5044: (45, 739), 5045: (42, 1577), 5046: (47, 1429),\n",
    "        #                   5047: (40, 815), 5048: [(42, 10), (48, 1087)], 5049: (49, 792), 5050: (50, 854),\n",
    "        #                   5051: (46, 1643), 5052: [(51, 271), (54, 9671), (55, 404)], 5053: (52, 564), 5054: (53, 601),\n",
    "        #                   5056: (55, 2333), 5057: [(57, 4152), (61, 427), (62, 515)], 5058: (59, 625), 5059: (43, 1016),\n",
    "        #                   5061: (60, 5577), 5062: (63, 622), 5063: (66, 556), 5064: (68, 4129), 5065: (68, 7563),\n",
    "        #                   5066: (69, 1123), 5067: (70, 1363), 5068: (70, 830), 5070: (73, 936), 5071: (76, 771),\n",
    "        #                   5072: (68, 558), 5073: (77, 6361), 5074: (79, 931), 5075: (80, 612), 5076: (81, 4991),\n",
    "        #                   5077: (82, 37691), 5078: (83, 3128), 5079: (84, 583), 5080: (85, 590), 5081: (86, 12492),\n",
    "        #                   5082: (87, 1895), 5083: (87, 2918), 5084: [(88, 333), (89, 696)], 5085: (90, 1344),\n",
    "        #                   5086: (91, 4840), 5087: (92, 3753), 5088: (93, 928), 5089: (94, 2910), 5090: (96, 724),\n",
    "        #                   5091: (98, 2752), 5092: (100, 757), 5093: [(103, 1321), (107, 1377)], 5094: (104, 2953),\n",
    "        #                   5095: (106, 9383), 5096: (108, 866), 5097: (109, 722), 5098: (104, 127), 5099: (111, 565),\n",
    "        #                   5100: (113, 8127), 5101: (112, 829), 5102: (114, 643), 5103: (115, 699), 5104: (116, 1178),\n",
    "        #                   5105: (117, 795)}\n",
    "    \n",
    "        \"\"\"\n",
    "        After all potential overlaps are found we need to deal with several possibilities.\n",
    "            1) Members of now_labs is not listed in direct_overlap.\n",
    "                These represent newly formed tracks and need a label, add to live_ccl, so not confused with live_ccl or dead_ccl.\n",
    "            2) Members of now_labs listed in direct_overlap.\n",
    "                These represent extensions/continuations of existing tracks.\n",
    "                 Members of now_labs with only a single link are only linked to one member of last_labs and need to take on that label.\n",
    "                 Members of now_labs with only a multiple links to last_labs are mergers of existing tracks.\n",
    "                    How choose which last_labs label to keep and which to move to dead_ccl (i.e., terminated tracks.)?\n",
    "            3) Members of last_labs not listed in direct_overlap.\n",
    "                These represent terminated tracks and need to be moved from live_ccl to dead_ccl.\n",
    "            4) Multiple members of now_labs point to the same member of last_labs.\n",
    "                These represent a possible beginning of a splitting/forking of an existing track or\n",
    "                multiple expansions/shifts in the spatial footprint of an existing track.\n",
    "                For now, these now_labs are just remapped to the same last_labs CCL.\n",
    "        \"\"\"\n",
    "        used_ccl = set()\n",
    "        all_past_ccl = sorted(live_ccl + dead_ccl)\n",
    "        used_ccl.update(all_past_ccl)\n",
    "        # Ensure any new CCL tracks get unique value\n",
    "        new_ccl = all_past_ccl[-1] + 1\n",
    "        for nl in now_labs:\n",
    "            if nl in direct_overlap:\n",
    "                ##\n",
    "                # Current CCL connects with Previous/existing CCL(s)\n",
    "                if isinstance(direct_overlap[nl], tuple):\n",
    "                    ##\n",
    "                    # Only a single back-connection between nl and the previous timestep; extend existing track.\n",
    "                    if local_verboser:\n",
    "                        mega_msg.append(f\"\\t\\t{nl:4d} -> {direct_overlap[nl][0]:4d} Single-Link\")\n",
    "                    ##\n",
    "                    # Update current CCL map\n",
    "                    lmap = np.where(lmap == nl, direct_overlap[nl][0], lmap)\n",
    "                    used_ccl.add(direct_overlap[nl][0])\n",
    "                else:\n",
    "                    ##\n",
    "                    # Multiple back-connections between nl and the previous timestep; a track merger.\n",
    "                    if local_verboser:\n",
    "                        mega_msg.append(f\"\\t\\t{nl:4d} -> {direct_overlap[nl]} Multi-Link\")\n",
    "                    ##\n",
    "                    # Find sizes of previous CCL (members of merge)\n",
    "                    sizes = [_[1] for _ in direct_overlap[nl]]\n",
    "                    max_idx = np.argmax(sizes)\n",
    "                    ##\n",
    "                    # Continue the largest of the previous CCL\n",
    "                    use_ll = direct_overlap[nl][max_idx][0]\n",
    "                    if local_verboser:\n",
    "                        mega_msg.append(f\"\\t\\t{nl:4d} -> {direct_overlap[nl][max_idx]} Selected\")\n",
    "                    ##\n",
    "                    # Update current CCL map\n",
    "                    lmap = np.where(lmap == nl, use_ll, lmap)\n",
    "                    used_ccl.add(use_ll)\n",
    "            else:\n",
    "                # Current CCL doesn't connect with Previous/existing CCL(s); it is a new track\n",
    "                if local_verboser:\n",
    "                    mega_msg.append(f\"\\t\\t{nl:4d} -> {new_ccl:4d} New CCL\")\n",
    "                ##\n",
    "                # Update current CCL map\n",
    "                lmap = np.where(lmap == nl, new_ccl, lmap)\n",
    "                used_ccl.add(new_ccl)\n",
    "                new_ccl += 1\n",
    "        now_labs = sorted(np.unique(lmap[lmap > 0]).tolist())\n",
    "        now_labs_set = set(now_labs)\n",
    "        if local_verbose:\n",
    "            mega_msg.append(f\"\\t\\tRemapped {now_labs = } ({len(now_labs)})\")\n",
    "        # print('\\n'.join(mega_msg)); return [], [], []\n",
    "    \n",
    "        ##\n",
    "        # Labels found in previous time-step but NOT now (i.e., Dead CCL)\n",
    "        if local_verbose:\n",
    "             mega_msg.append(\"\\t\\tLooking for new dead labels\")\n",
    "        dead_ccl_set = set(dead_ccl)\n",
    "        killed_labs = sorted(list(last_labs_set.difference(now_labs_set)))\n",
    "        if local_verbose:\n",
    "             mega_msg.append(f\"\\t\\t\\t{killed_labs = } ({len(killed_labs)})\")\n",
    "        if killed_labs:\n",
    "            killed_labs_set = set(killed_labs)\n",
    "            killed_labs = sorted(list(killed_labs_set.difference(dead_ccl_set)))\n",
    "            if local_verbose:\n",
    "                 mega_msg.append(f\"\\t\\t\\t*{killed_labs = } ({len(killed_labs)})\")\n",
    "        if killed_labs:\n",
    "            # Ensure killed_labs not already in dead_ccl\n",
    "            killed_labs_set = set(killed_labs)\n",
    "            killed_labs = sorted(list(killed_labs_set.difference(dead_ccl_set)))\n",
    "            if local_verbose:\n",
    "                 mega_msg.append(f\"\\t\\t\\t**{killed_labs = } ({len(killed_labs)})\")\n",
    "                 mega_msg.append(f\"\\t\\t\\t{dead_ccl = } ({len(dead_ccl)})\")\n",
    "                 mega_msg.append(f\"\\t\\t\\t{live_ccl = } ({len(live_ccl)})\")\n",
    "            # Is killed_labs conflicting with dead_ccl?\n",
    "            kmap = {}\n",
    "            all_past_ccl = sorted(live_ccl + dead_ccl)\n",
    "            for kl in killed_labs:\n",
    "                if kl in dead_ccl:\n",
    "                    # kl already used. Assign it a new label not one already in dead_ccl or live_ccl\n",
    "                    nu_lab = all_past_ccl[-1] + 1\n",
    "                    kmap[kl] = nu_lab\n",
    "                    dead_ccl.append(nu_lab)\n",
    "                else:\n",
    "                    dead_ccl.append(kl)\n",
    "            dead_ccl = sorted(list(set(dead_ccl)))\n",
    "            killed_labs = [(kmap[_] if _ in kmap else _) for _ in killed_labs]\n",
    "            live_ccl = [_ for _ in live_ccl if _ not in killed_labs]\n",
    "            if local_verbose:\n",
    "                 mega_msg.append(f\"\\t\\t\\t***{killed_labs = } ({len(killed_labs)})\")\n",
    "                 mega_msg.append(f\"\\t\\t\\t*{dead_ccl = } ({len(dead_ccl)})\")\n",
    "                 mega_msg.append(f\"\\t\\t\\t*{live_ccl = } ({len(live_ccl)})\")\n",
    "    \n",
    "        ##\n",
    "        # Labels found now but NOT in previous time-step (i.e., New CCL)\n",
    "        new_ccl = sorted(list(now_labs_set.difference(last_labs_set)))\n",
    "        # Is new_ccl conflicting with live_ccl?\n",
    "        nmap = {}\n",
    "        all_past_ccl = sorted(live_ccl + dead_ccl)\n",
    "        if local_verbose:\n",
    "             mega_msg.append(\"\\t\\tLooking for new labels\")\n",
    "             mega_msg.append(f\"\\t\\t\\t{all_past_ccl = } ({len(all_past_ccl)})\")\n",
    "        if new_ccl:\n",
    "            if local_verbose:\n",
    "                 mega_msg.append(f\"\\t\\t\\t{new_ccl = } ({len(new_ccl)})\")\n",
    "            for nl in new_ccl[::-1]:\n",
    "                # Check if nl used in past\n",
    "                if nl in all_past_ccl:\n",
    "                    # nl already used. Assign it a new label not one already in all_past_ccl\n",
    "                    nu_lab = all_past_ccl[-1] + 1\n",
    "                    nmap[nl] = nu_lab\n",
    "                    live_ccl.append(nu_lab)\n",
    "                else:\n",
    "                    # No conflict\n",
    "                    live_ccl.append(nl)\n",
    "            for nl in nmap.keys():\n",
    "                new_ccl = [(nmap[nl] if _ == nl else _) for _ in new_ccl]\n",
    "                new_ccl = sorted(new_ccl)\n",
    "                lmap = np.where(lmap == nl, nmap[nl], lmap)\n",
    "            live_ccl = sorted(list(set(live_ccl)))\n",
    "            if local_verbose:\n",
    "                 mega_msg.append(f\"\\t\\t\\t*{new_ccl = } ({len(new_ccl)})\")\n",
    "                 mega_msg.append(f\"\\t\\t\\t*{live_ccl = } ({len(live_ccl)})\")\n",
    "    \n",
    "        # print('\\n'.join(mega_msg)); return [], [], []\n",
    "    \n",
    "        # # ## *\n",
    "        # # # Rename any conflicted_labs\n",
    "        # # re_name = {}\n",
    "        # # if conflicted_labs:\n",
    "        # #     for clab_past in conflicted_labs:\n",
    "        # #         local_verboseif local_verbose:\n",
    "        # #             print(f\"\\tPast {clab_past}\")\n",
    "        # #         for clab_now in conflicted_labs:\n",
    "        # #             if local_verbose:\n",
    "        # #                 print(f\"\\t\\tNow  {clab_now}\")\n",
    "        # #             ##\n",
    "        # #             # Does the current clab intersect with the clab_past?\n",
    "        # #             cmap_hit = np.asarray((lmap == clab_now) & (lmap_prev == clab_past)).nonzero()\n",
    "        # #             if local_verbose:\n",
    "        # #                 print(f\"\\t\\t\\t{cmap_hit  = }\")\n",
    "        # #             if cmap_hit[0].tolist():\n",
    "        # #                 re_name[clab_now] = clab_past\n",
    "        # #                 if local_verbose:\n",
    "        # #                     print(f\"\\t\\t\\tCurrent {clab_now} -> Past {clab_past}\")\n",
    "        # #     lmap_old = np.copy(lmap)\n",
    "        # #     for clab_ in conflicted_labs[::-1]:\n",
    "        # #         if clab_ in re_name:\n",
    "        # #             lmap = np.where(lmap_old == clab_, re_name[clab_], lmap)\n",
    "        # #     now_labs = sorted(np.unique(lmap[lmap > 0]).tolist())\n",
    "        # #     if local_verbose:\n",
    "        # #         print(f\"\\t\\tNew {now_labs = }\")\n",
    "    \n",
    "        # if local_verbose:\n",
    "        #     print('\\n'.join(mega_msg))\n",
    "    \n",
    "        return lmap, live_ccl, dead_ccl, mega_msg\n",
    "    ###############################################################################\n",
    "    \n",
    "    \"\"\" \"\"\"\n",
    "    mega_msg = []\n",
    "    local_verbose = [False, True][0]\n",
    "    make_mask = [False, True][0]\n",
    "    find_ccl = [False, True][0]\n",
    "    ncores = 4\n",
    "    track_ccl = [False, True][0]\n",
    "\n",
    "    ##\n",
    "    # Define data grid\n",
    "\n",
    "    # grid mid-points [-89.95, 89.95] so to -90 to +90 with edges\n",
    "    #   lats = [-89.95, -89.85, ... -0.05, 0.05, ... 89.85, 89.95]\n",
    "    nlats = 1800\n",
    "    dlat = 0.1\n",
    "    lats = np.arange(-89.95, 90.0, dlat)\n",
    "\n",
    "    # grid mid-points [-179.95, 179.95] so to -180 to +180 with edges\n",
    "    #   lons = [-179.95, -179.85, ... -0.05, 0.05, ... 179.85, 179.95]\n",
    "    nlons = 3600\n",
    "    dlon = 0.1\n",
    "    lons = np.arange(-179.95, 180.0, dlon)\n",
    "\n",
    "    ##\n",
    "    # Find row separating NH and SH\n",
    "    difference_array = np.absolute(lats - 0)\n",
    "    # find the index of minimum element from the array\n",
    "    nh_0 = difference_array.argmin()\n",
    "    sh_0 = nh_0 - 1\n",
    "    # print(f\"{sh_0} {lats[sh_0]}\")\n",
    "    # print(f\"{nh_0} {lats[nh_0]}\")\n",
    "    maxid = nlats * nlons\n",
    "    row_start = tuple([_ for _ in range(maxid) if _ % nlons == 0])\n",
    "    row_end = tuple([_ + (nlons - 1) for _ in row_start])\n",
    "    # (3239999, 3240000) (row_end[sh_0], row_start[nh_0])\n",
    "    hemi_sep = (row_end[sh_0], row_start[nh_0])\n",
    "    # print(hemi_sep)\n",
    "\n",
    "    ntimes = len(flist)\n",
    "\n",
    "    # Note changes to pr_floor require rerunning make_mask\n",
    "    pr_floor = 0.1 / 3600.0; floor_tag = \"01mmhr\"   # 0.1 mm/hr as mm/s\n",
    "    # pr_floor = 0.25 / 3600.0; floor_tag = \"025mmhr\"  # 0.25 mm/hr as mm/s\n",
    "    # pr_floor = 0.5 / 3600.0; floor_tag = \"05mmhr\"  # 0.5 mm/hr as mm/s\n",
    "    # pr_floor = 1.0 / 3600.0; floor_tag = \"1mmhr\"  # 1 mm/hr as mm/s\n",
    "    # pr_floor = 10.0 / 3600.0 # 10 mm/hr as mm/s\n",
    "    # pr_floor = 20.0 / 3600.0 # 100 mm/hr as mm/s\n",
    "\n",
    "    dyamond_mask_file = dyamond_mask_file.replace(\".npy\", f\"_{floor_tag}.npy\")\n",
    "    dyamond_ccl_initial_file = dyamond_ccl_initial_file.replace(\".pkl\", f\"_{floor_tag}.pkl\")\n",
    "    dyamond_ccl_file = dyamond_ccl_file.replace(\".pkl\", f\"_{floor_tag}.pkl\")\n",
    "    if just_48:\n",
    "        dyamond_mask_file = dyamond_mask_file.replace(\".npy\", \"_48.npy\")\n",
    "        dyamond_ccl_initial_file = dyamond_ccl_initial_file.replace(\".pkl\", \"_48.pkl\")\n",
    "        dyamond_ccl_file = dyamond_ccl_file.replace(\".pkl\", \"_48.pkl\")\n",
    "\n",
    "    dl_lon_idx = 1800 # -0.05 0.05 0.15\n",
    "\n",
    "    times = np.zeros(ntimes, dtype='datetime64[m]')\n",
    "    for tidx, atime_str in enumerate(dt_str):\n",
    "        # print(f\"{tidx:4d} {atime_str}\")\n",
    "        tmp_ = atime_str.split(\" \")\n",
    "        tmp__ = tmp_[-2].split(\":\")\n",
    "        times[tidx] = np.datetime64(f'{tmp_[0]}-{tmp_[1]}-{tmp_[2]}T{tmp__[0]}:{tmp__[1]}')\n",
    "\n",
    "    # Best dtype to minimize array memory footprint\n",
    "    #\n",
    "    #   Note: (see numpy.result_type)\n",
    "    #       * When both scalars and arrays are used, the array’s type takes precedence and the actual value of the scalar is taken into account.\n",
    "    #       * When two arrays are used in a numpy calculaton 'min_scalar_type' is called on each array and the resulting data types are all\n",
    "    #           combined with 'promote_types' to produce the return value. Many times this results in native 64-bit results.\n",
    "    #\n",
    "    # Masks usually hold positive integer 0/1 or bool\n",
    "    #    8-bit boolean          (bool, 'True'/'False', 1/0) has 1/8 the memory footprint of int64/float64\n",
    "    #    8-bit unsigned integer (uint8, 0 to 255)           has 1/8 the memory footprint of int64/float64\n",
    "    #   16-bit unsigned integer (uint16, 0 to 65535)        has 1/4 the memory footprint of int64/float64\n",
    "    #   32-bit unsigned integer (uint32, 0 to 4294967295)   has 1/2 the memory footprint of int64/float64\n",
    "    #   i4 = int32  f4 = float32    32-bit integer and floating-point number\n",
    "    #   i8 = int64  f8 = float64    64-bit integer and floating-point number\n",
    "    mask_dtype = bool\n",
    "    mask_dtype_alt = np.uint8\n",
    "    float_dtype_alt = np.float32\n",
    "    int_dtype_alt = np.int32\n",
    "    int_dtype_alt = np.int16\n",
    "\n",
    "    ##\n",
    "    # Read raw IMERG files, make 0/1 mask and save.\n",
    "    if make_mask:\n",
    "        # (ntimes, nlats, nlons)\n",
    "        # pr = np.zeros((ntimes, nlats, nlons), dtype=np.float32)\n",
    "        masked_pr_flag = np.zeros((ntimes, nlats, nlons), dtype=mask_dtype)\n",
    "        print(\"\\nMaking Mask... \")\n",
    "        loop_src = flist if local_verbose else tqdm(flist, total=ntimes, desc=f\"Reading NetCDF\")\n",
    "        for midx, mfile in enumerate(loop_src):\n",
    "            if local_verbose:\n",
    "                print(f\"{midx: 03d}: {mfile}\")\n",
    "\n",
    "            ##\n",
    "            # Open a file\n",
    "            ds = netCDF4.Dataset(mfile)\n",
    "\n",
    "            ##\n",
    "            # Read PR Field\n",
    "            #   (1, 1800, 3600) numpy.ma.core.MaskedArray numpy.float32\n",
    "            _pr = ds.variables[\"PRECTOT\"][:]\n",
    "            #   (1800, 3600)\n",
    "            _pr = _pr.squeeze()\n",
    "\n",
    "            ##\n",
    "            # Remove mask\n",
    "            _pr = ma.filled(_pr, 0)\n",
    "\n",
    "            ds.close()\n",
    "\n",
    "            ##\n",
    "            # Mask with PR < 0.1 mm/hr\n",
    "            _pr = np.where(_pr >= pr_floor, 1, 0)\n",
    "            # pr_mask = np.nonzero(_pr >= pr_floor)\n",
    "            pr_mask = np.nonzero(_pr)\n",
    "            # if midx == 0:\n",
    "            #     # Save as netcdf\n",
    "            #     dyamond_mask_file_nc = dyamond_mask_file.replace(\".npy\", \".nc\")\n",
    "            #     ncfile = netCDF4.Dataset(dyamond_mask_file_nc, mode='w', format='NETCDF4_CLASSIC')\n",
    "            #     lat_dim = ncfile.createDimension('lat', nlats) # latitude axis\n",
    "            #     lon_dim = ncfile.createDimension('lon', nlons) # longitude axis\n",
    "            #     lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "            #     lat.units = 'degrees_north'\n",
    "            #     lat.long_name = 'latitude'\n",
    "            #     lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "            #     lon.units = 'degrees_east'\n",
    "            #     lon.long_name = 'longitude'\n",
    "            #     cclmap = ncfile.createVariable('cclmap', np.float32, ('lat', 'lon'))\n",
    "            #     lat[:] = lats\n",
    "            #     lon[:] = lons\n",
    "            #     cclmap[:, :] = _pr\n",
    "            #     ncfile.close()\n",
    "\n",
    "            del _pr\n",
    "            masked_pr_flag[midx, pr_mask[0], pr_mask[1]] = True\n",
    "            del pr_mask\n",
    "\n",
    "            # break\n",
    "\n",
    "        ##\n",
    "        # Roll so dateline is not on the map edges\n",
    "        # masked_pr_flag = np.roll(masked_pr_flag, dl_lon_idx, axis=2)\n",
    "\n",
    "        # ##\n",
    "        # # Trim off Spatial extras\n",
    "        # #   (4320, 900, 3600) -> (4320, :t_edge + 1, l_edge:r_edge + 1) or (4320, 701, 1400)\n",
    "        # r_edge = 2599\n",
    "        # l_edge = 1200\n",
    "        # t_edge = 700\n",
    "        # masked_pr_flag = masked_pr_flag[:, :t_edge + 1, l_edge:r_edge + 1]\n",
    "\n",
    "        ##\n",
    "        # Save\n",
    "        print(f\"Saving Mask to {dyamond_mask_file}\")\n",
    "        np.save(dyamond_mask_file, masked_pr_flag)\n",
    "\n",
    "        print(\"\\n\\tRerun with make_mask == False\\n\")\n",
    "        os._exit(0)\n",
    "    else:\n",
    "        if find_ccl:\n",
    "            print(\"\\nReading Mask... \")\n",
    "            masked_pr_flag = np.load(dyamond_mask_file)\n",
    "\n",
    "    if find_ccl:\n",
    "        # ##\n",
    "        # # Find current 3D CCL\n",
    "        # print(\"\\nFinding CCL Field... \")\n",
    "        # # ccl_map = cc3d.connected_components(masked_pr_flag, delta=0, connectivity=use_connectivity, return_N=False)\n",
    "        # # ccl_map = cc3d.dust(ccl_map, threshold=20000, connectivity=use_connectivity, in_place=True)\n",
    "        # ##\n",
    "        # # Save\n",
    "        # np.save(dyamond_ccl_file, ccl_map)\n",
    "\n",
    "        ##\n",
    "        # Find current 2D CCL and connect over time and wrap around dateline\n",
    "        #   Store CCL (features) as timeseries map for time tracking.\n",
    "        #   Each day (48 files) takes ~min on 8-core i7 CPU\n",
    "        ######\n",
    "        # Hai: run the entire process with single-threaded fashion\n",
    "        ######\n",
    "        # print(f\"\\nFinding CCL Field... for {ntimes}\")\n",
    "        # ccl_files = []\n",
    "        # with Pool(ncores) as pool:\n",
    "        #     results = pool.starmap(get_ccl, [(tidx, masked_pr_flag[tidx, :, :], min_voxels, use_connectivity, f\"{hidden_path}get_ccl_{min_voxels:03d}_{floor_tag}_{tidx:05d}.npy\") for tidx in range(ntimes)])\n",
    "        #     for res in results:\n",
    "        #         ccl_files.append(res)\n",
    "        # del res, results\n",
    "        # print(\"Saved {len(ccl_files)}\")\n",
    "        ##############################################################\n",
    "        \n",
    "        print(f\"\\nFinding CCL Field... for {ntimes}\")\n",
    "        ccl_files = []\n",
    "        \n",
    "        # Process each item in sequence instead of using multiple threads\n",
    "        for tidx in range(ntimes):\n",
    "            # Call `get_ccl` function for each `tidx`\n",
    "            res = get_ccl(\n",
    "                tidx,\n",
    "                masked_pr_flag[tidx, :, :],\n",
    "                min_voxels,\n",
    "                use_connectivity,\n",
    "                f\"{hidden_path}get_ccl_{min_voxels:03d}_{floor_tag}_{tidx:05d}.npy\"\n",
    "            )\n",
    "            ccl_files.append(res)\n",
    "        \n",
    "        print(f\"Saved {len(ccl_files)}\")\n",
    "\n",
    "        ##############################################################\n",
    "\n",
    "        ##\n",
    "        # Relabel so contiguous range within time step\n",
    "        ccl_super_map = np.zeros((ntimes, nlats, nlons), dtype=np.int16)\n",
    "        for tidx in range(ntimes):\n",
    "            cclf = f\"{hidden_path}get_ccl_{min_voxels:03d}_{floor_tag}_{tidx:05d}.npy\"\n",
    "            print(f\"Reading {cclf}\")\n",
    "            ccl_map = np.load(cclf)\n",
    "            now_ccl = sorted(np.unique(ccl_map[ccl_map > 0]).tolist())\n",
    "            # print(f\"{now_ccl = }\")\n",
    "            # Offset so can rename without conflicts\n",
    "            new_ccl = now_ccl[-1]\n",
    "            for old_ccl in now_ccl:\n",
    "                new_ccl += 1\n",
    "                # print(f\"{old_ccl = } {new_ccl = }\")\n",
    "                ccl_map[ccl_map == old_ccl] = new_ccl\n",
    "            # Remove offset so first CCL == 1\n",
    "            ccl_map = np.where(ccl_map > 0, ccl_map - now_ccl[-1], 0)\n",
    "            ccl_super_map[tidx, :, :] = ccl_map\n",
    "        ##\n",
    "        # Save\n",
    "        print(f\"Saved {dyamond_ccl_initial_file}\")\n",
    "        with open(dyamond_ccl_initial_file, 'wb') as f:\n",
    "            pickle.dump(ccl_super_map, f)\n",
    "    else:\n",
    "        if track_ccl:\n",
    "            print(\"\\nReading CCL Field... \")\n",
    "            with open(dyamond_ccl_initial_file, 'rb') as f:\n",
    "                ccl_super_map = pickle.load(f)\n",
    "\n",
    "    # ##\n",
    "    # # Debug\n",
    "    # tidx = 0\n",
    "    # ccl_map = ccl_super_map[tidx, :, :]\n",
    "    # now_ccl = sorted(np.unique(ccl_map[ccl_map > 0]).tolist())\n",
    "    # n_ccl = len(now_ccl)\n",
    "    # print(f\"\\tnow_ccl  ({n_ccl:4d}): {now_ccl}\\n\\n\")\n",
    "    # basic_plot(ccl_map, lons, lats, str(np.datetime_as_string(times[tidx], unit='m')), f\"{hidden_path}ccl_map_{min_voxels:03d}_{floor_tag}_{tidx:04d}.png\")\n",
    "    # os._exit(0)\n",
    "\n",
    "    if track_ccl:\n",
    "        # # Debug\n",
    "        # for tidx in range(ntimes):\n",
    "        #     ccl_mapb = ccl_super_map[tidx, :, :]\n",
    "        #     now_ccl = sorted(np.unique(ccl_mapb[ccl_mapb > 0]).tolist())\n",
    "        #     n_ccl = len(now_ccl)\n",
    "        #     print(f\"\\tnow_ccl  ({n_ccl:4d}): {now_ccl}\\n\\n\")\n",
    "        #     for cc in now_ccl:\n",
    "        #         ccl_mapc = np.where(ccl_mapb == int(cc), ccl_mapb, 0)\n",
    "        #         print(f\"{cc:5d} = {np.count_nonzero(ccl_mapc)}\")\n",
    "        #         basic_plot(ccl_mapc, lons, lats, str(np.datetime_as_string(times[tidx], unit='m')), f\"{hidden_path}ccl_map_{tidx:04d}_ccl{int(cc):05d}.png\")\n",
    "        #     if tidx == 1:\n",
    "        #         os._exit(1)\n",
    "        # os._exit(1)\n",
    "\n",
    "        # for tidx in range(ntimes):\n",
    "        #     ccl_mapb = ccl_super_map[tidx, :, :]\n",
    "        #     now_ccl = sorted(np.unique(ccl_mapb[ccl_mapb > 0]).tolist())\n",
    "        #     n_ccl = len(now_ccl)\n",
    "        #     print(f\"\\tnow_ccl  ({n_ccl:4d}): {now_ccl}\\n\\n\")\n",
    "        #     basic_plot(ccl_mapb, lons, lats, str(np.datetime_as_string(times[tidx], unit='m')), f\"{hidden_path}ccl_map_{tidx:04d}.png\")\n",
    "        #     if tidx == 2:\n",
    "        #         os._exit(1)\n",
    "        # os._exit(1)\n",
    "\n",
    "        ##\n",
    "        # Find current 2D CCL and connect over time and wrap around dateline\n",
    "        # Stored CCL (features) up to the previous time step\n",
    "        live_ccl = []\n",
    "        # Stored CCL (features) that have been retired (i.e., not present in the previous time step)\n",
    "        dead_ccl = []\n",
    "        # ccl_final_map = np.zeros((ntimes, nlats, nlons), dtype=np.int16)\n",
    "        prev_ccl_map = []\n",
    "        # All Stored CCL (features) = live_ccl + dead_ccl\n",
    "        loop_src = range(ntimes) if local_verbose else tqdm(range(ntimes), desc=f\"Finding CCL\")\n",
    "        for tidx in loop_src:\n",
    "            if local_verbose:\n",
    "                mega_msg.append(f\"\\nTime Index {tidx:3d}\")\n",
    "                if live_ccl:\n",
    "                    mega_msg.append(f\"\\tlive_ccl ({len(live_ccl)}): [{live_ccl[0]} ... {live_ccl[-1]}]\")\n",
    "                else:\n",
    "                    mega_msg.append(f\"\\tlive_ccl ({len(live_ccl)})\")\n",
    "                if dead_ccl:\n",
    "                    mega_msg.append(f\"\\tdead_ccl ({len(dead_ccl)}): [{dead_ccl[0]} ... {dead_ccl[-1]}]\")\n",
    "                else:\n",
    "                    mega_msg.append(f\"\\tdead_ccl ({len(dead_ccl)})\")\n",
    "            ccl_map = ccl_super_map[tidx, :, :]\n",
    "            now_ccl = sorted(np.unique(ccl_map[ccl_map > 0]).tolist())\n",
    "\n",
    "            # # Debug limit to 5 CCL\n",
    "            # now_ccl = now_ccl[:5]\n",
    "            # new_ccl_map = np.zeros((nlats, nlons), dtype=np.int16)\n",
    "            # for nl in now_ccl:\n",
    "            #     new_ccl_map = np.where(ccl_map == nl, ccl_map, new_ccl_map)\n",
    "            # ccl_map = new_ccl_map\n",
    "            # now_ccl = sorted(np.unique(ccl_map[ccl_map > 0]).tolist())\n",
    "            # n_ccl = len(now_ccl)\n",
    "            # print(f\"\\tnow_ccl pre-tracking  ({n_ccl:4d}): [{now_ccl[0]} ... {now_ccl[-1]}]\")\n",
    "\n",
    "            if local_verbose:\n",
    "                n_ccl = len(now_ccl)\n",
    "                if now_ccl:\n",
    "                    mega_msg.append(f\"\\tnow_ccl pre-tracking  ({n_ccl:4d}): [{now_ccl[0]} ... {now_ccl[-1]}]\")\n",
    "                else:\n",
    "                    mega_msg.append(f\"\\tnow_ccl pre-tracking  ({n_ccl:4d}):\")\n",
    "            if tidx == 0:\n",
    "                ##\n",
    "                # Initial Pass, all current CCL see as live (new features)\n",
    "                live_ccl = now_ccl[:]\n",
    "                prev_ccl_map = ccl_map\n",
    "                ##\n",
    "                # Store the CCL map (features)\n",
    "                cclf = f\"{hidden_path}ccl_map_{min_voxels:03d}_{floor_tag}_{tidx:05d}.npy\"\n",
    "                np.save(cclf, ccl_map)\n",
    "                continue\n",
    "\n",
    "            ##\n",
    "            # Connect/track new CCL to live features or create new features.\n",
    "            #   Updates ccl_map, live_ccl and dead_ccl\n",
    "            ccl_map, live_ccl, dead_ccl, msg = track_labels(prev_ccl_map, ccl_map, live_ccl, dead_ccl, hemi_sep)\n",
    "            if msg:\n",
    "                mega_msg.extend(msg)\n",
    "            now_ccl = sorted(np.unique(ccl_map[ccl_map > 0]).tolist())\n",
    "            n_ccl = len(now_ccl)\n",
    "            prev_ccl_map = ccl_map\n",
    "\n",
    "            # # Debug\n",
    "            # basic_plot(ccl_map, lons, lats, str(np.datetime_as_string(times[tidx], unit='m')), f\"{hidden_path}ccl_map_{tidx:04d}.png\")\n",
    "            # # Save as netcdf\n",
    "            # dyamond_mask_file_nc = f\"{hidden_path}ccl_map_{tidx:04d}.nc\"\n",
    "            # ncfile = netCDF4.Dataset(dyamond_mask_file_nc, mode='w', format='NETCDF4_CLASSIC')\n",
    "            # lat_dim = ncfile.createDimension('lat', nlats) # latitude axis\n",
    "            # lon_dim = ncfile.createDimension('lon', nlons) # longitude axis\n",
    "            # lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "            # lat.units = 'degrees_north'\n",
    "            # lat.long_name = 'latitude'\n",
    "            # lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "            # lon.units = 'degrees_east'\n",
    "            # lon.long_name = 'longitude'\n",
    "            # cclmap = ncfile.createVariable('cclmap', np.float32, ('lat', 'lon'))\n",
    "            # lat[:] = lats\n",
    "            # lon[:] = lons\n",
    "            # cclmap[:, :] = ccl_map\n",
    "            # ncfile.close()\n",
    "            # break\n",
    "\n",
    "            ##\n",
    "            # Store the CCL map (features)\n",
    "            cclf = f\"{hidden_path}ccl_map_{min_voxels:03d}_{floor_tag}_{tidx:05d}.npy\"\n",
    "            np.save(cclf, ccl_map)\n",
    "            if local_verbose:\n",
    "                mega_msg.append(f\"\\tTracked now_ccl ({n_ccl}): -> {cclf}\")\n",
    "                if now_ccl:\n",
    "                    mega_msg.append(f\"\\tnow_ccl  ({n_ccl:4d}): [{now_ccl[0]} ... {now_ccl[-1]}]\")\n",
    "                else:\n",
    "                    mega_msg.append(f\"\\tnow_ccl  ({n_ccl:4d}):\")\n",
    "                if live_ccl:\n",
    "                    mega_msg.append(f\"\\tlive_ccl ({len(live_ccl):4d}): [{live_ccl[0]} ... {live_ccl[-1]}]\")\n",
    "                else:\n",
    "                    mega_msg.append(f\"\\tlive_ccl ({len(live_ccl):4d}):\")\n",
    "                if dead_ccl:\n",
    "                    mega_msg.append(f\"\\tdead_ccl ({len(dead_ccl):4d}): [{dead_ccl[0]} ... {dead_ccl[-1]}]\")\n",
    "                else:\n",
    "                    mega_msg.append(f\"\\tdead_ccl ({len(dead_ccl):4d}):\")\n",
    "    else:\n",
    "        # # ccl_final_map = np.zeros((ntimes, nlats, nlons), dtype=np.int16)\n",
    "        # loop_src = range(ntimes) if local_verbose else tqdm(range(ntimes), desc=f\"Finding CCL\")\n",
    "        # for tidx in loop_src:\n",
    "        #     cclf = f\"{hidden_path}ccl_map_{min_voxels:03d}_{floor_tag}_{tidx:05d}.npy\"\n",
    "        #     ccl_map = np.load(cclf)\n",
    "        #     # ccl_final_map[tidx, :, :] = ccl_map\n",
    "\n",
    "        #     now_ccl = sorted(np.unique(ccl_map[ccl_map > 0]).tolist())\n",
    "        #     n_ccl = len(now_ccl)\n",
    "        #     mega_msg.append(f\"{tidx:5d} {n_ccl:5d} {now_ccl[0]:5d} {now_ccl[-1]:5d} {str(np.datetime_as_string(times[tidx], unit='m'))}\")\n",
    "\n",
    "        #     # Debug\n",
    "        #     # basic_plot(ccl_map, lons, lats, str(np.datetime_as_string(times[tidx], unit='m')), f\"{hidden_path}tracked_ccl_map_{tidx:04d}.png\")\n",
    "\n",
    "        #     # if tidx > 10:\n",
    "        #     #     break\n",
    "        # print('\\n'.join(mega_msg)); return [], [], []\n",
    "\n",
    "\n",
    "        # ffmpeg -framerate 48 -pattern_type glob -i '*.png' -vcodec libx264 -pix_fmt yuv420p -s 1920x1080 -crf 0 ccl_1080p.mp4\n",
    "\n",
    "        ######\n",
    "        # Hai: run the entire process with single-threaded fashion\n",
    "        ######\n",
    "        # with Pool(ncores) as pool:\n",
    "        #     results = pool.starmap(basic_plot_pool, [(f\"{hidden_path}ccl_map_{min_voxels:03d}_{floor_tag}_{tidx:05d}.npy\", lons, lats,  str(np.datetime_as_string(times[tidx], unit='m')), f\"{hidden_path}tracked_ccl_map_{tidx:04d}.png\") for tidx in range(ntimes)])\n",
    "        #     for res in results:\n",
    "        #         print(f\"Done {res}\")\n",
    "        # del res, results\n",
    "        ##############################################################\n",
    "        \n",
    "        # Process each item in sequence instead of using multiple threads\n",
    "        for tidx in range(ntimes):\n",
    "            # Call `basic_plot_pool` function for each `tidx`\n",
    "            res = basic_plot_pool(\n",
    "                f\"{hidden_path}ccl_map_{min_voxels:03d}_{floor_tag}_{tidx:05d}.npy\",\n",
    "                lons,\n",
    "                lats,\n",
    "                str(np.datetime_as_string(times[tidx], unit='m')),\n",
    "                f\"{hidden_path}tracked_ccl_map_{tidx:04d}.png\"\n",
    "            )\n",
    "            print(f\"Done {res}\")\n",
    "        \n",
    "        del res\n",
    "        ##############################################################\n",
    "\n",
    "\n",
    "    #     ##\n",
    "    #     # Save\n",
    "    #     mega_msg.append(f\"Saved {dyamond_ccl_file}\")\n",
    "    #     with open(dyamond_ccl_file, 'wb') as f:\n",
    "    #         pickle.dump(ccl_final_map, f)\n",
    "    # else:\n",
    "    #     with open(dyamond_ccl_file, 'rb') as f:\n",
    "    #         ccl_final_map = pickle.load(f)\n",
    "\n",
    "    print('\\n'.join(mega_msg)); return [], [], []\n",
    "\n",
    "    # for tidx in range(ntimes):\n",
    "    #     imerg_map = ccl_map[tidx, :, :]\n",
    "    #     now_ccl = sorted(np.unique(imerg_map[imerg_map > 0]).tolist())\n",
    "    #     print(f\"{tidx:4d} Now CCL {len(now_ccl)}\")\n",
    "\n",
    "    #     pname = f\"{hidden_path}ccl_{tidx:04d}.png\"\n",
    "    #     a_time_str = str(np.datetime_as_string(times[tidx], unit='m'))\n",
    "    #     basic_plot(imerg_map, lons, lats, f'{a_time_str.replace(\"T\", \"-\")} UTC', pname)\n",
    "    #     break\n",
    "\n",
    "    return\n",
    "\n",
    "# ---Start of main code block.\n",
    "def process_data(dir_list):\n",
    "    from dask.distributed import get_worker\n",
    "    \n",
    "    key_var = \"PRECTOT\" # [kg m-2 s-1] or [mm/s]\n",
    "    just_48 = [False, True][0]\n",
    "\n",
    "    ##\n",
    "    # Get DYAMONDv2 files\n",
    "    base_data_path = [\"/bayesics/p4/POMD/discover/\", \"/media/mbauer/bigd/data/POMD/discover/\"][0]\n",
    "    # dir_list = (\"202001\", \"202002\")\n",
    "    hidden_path = [\"/bayesics/p4/POMD_output/\", \"/media/mbauer/bigd/hidden/imergview/\"][0]\n",
    "\n",
    "    use_connectivity = 26\n",
    "    use_connectivity = 8\n",
    "    \n",
    "    min_voxels = [625, 400, 225, 100, 0][0]\n",
    "    dyamond_ccl_initial_file = f\"{hidden_path}dyamond_ccl_{use_connectivity:02d}_{min_voxels:03d}.pkl\"\n",
    "    dyamond_ccl_file = f\"{hidden_path}dyamond_ccl_{use_connectivity:02d}_{min_voxels:03d}.pkl\"\n",
    "    dyamond_mask_file = f\"{hidden_path}dyamond_raw_pr_{min_voxels:03d}.npy\"\n",
    "\n",
    "    ##\n",
    "    # Find all files\n",
    "    file_list = sorted([f\"{base_data_path}{base_path}/{_}\" for base_path in dir_list for _ in os.listdir(f\"{base_data_path}{base_path}/\") if _.endswith('.nc4')])\n",
    "\n",
    "    if just_48:\n",
    "        file_list = file_list[:48]\n",
    "\n",
    "    nfiles = len(file_list)\n",
    "\n",
    "    ##\n",
    "    # Extract Datetimes\n",
    "    dtime_str = []\n",
    "    dtime_dt = []\n",
    "    for afile in file_list:\n",
    "        tmp_ = afile.split(\"/\")[-1]\n",
    "        tmpa_ = tmp_.split(\".\")[-2]\n",
    "        tmpb_ = tmpa_.split(\"_\")\n",
    "        yyyy_str = tmpb_[0][:4]\n",
    "        mm_str = tmpb_[0][4:6]\n",
    "        dd_str = tmpb_[0][6:8]\n",
    "        hh_str = tmpb_[1][:2]\n",
    "        min_str = tmpb_[1][2:4]\n",
    "\n",
    "        dtime_str.append(f\"{yyyy_str} {mm_str} {dd_str} {hh_str}:{min_str} UTC\")\n",
    "        dtime_dt.append(np.datetime64(f'{yyyy_str}-{mm_str}-{dd_str}T{hh_str}:{min_str}'))\n",
    "\n",
    "    print(\"dir_list:\", dir_list)\n",
    "    pf_search(file_list, dtime_str, dyamond_mask_file, use_connectivity, dyamond_ccl_initial_file,\n",
    "              dyamond_ccl_file, hidden_path, min_voxels, just_48)\n",
    "    worker = get_worker()\n",
    "    worker_info = f\"Worker address: {worker.address}, Worker ID: {worker.id}\"\n",
    "    return f\"Processed {dir_list} at {worker_info}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e30b72-4850-49d2-84d0-9039f2a424ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(name=\"coiled-cluster\", container=\"tonhai/imerg-coiled-11.2024\", n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "256a1ab2-0b4d-4a3e-8fb5-49448654255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41148b2a-c093-4920-b9f2-da387f3f2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data1(dir_list):\n",
    "    from dask.distributed import get_worker\n",
    "    \n",
    "    key_var = \"PRECTOT\"  # [kg m-2 s-1] or [mm/s]\n",
    "    just_48 = [False, True][0]\n",
    "    base_data_path = [\"/bayesics/p4/POMD/discover/\", \"/media/mbauer/bigd/data/POMD/discover/\"][0]\n",
    "    hidden_path = [\"/bayesics/p4/POMD/output/\", \"/media/mbauer/bigd/hidden/imergview/\"][0]\n",
    "    # Get worker information\n",
    "    worker = get_worker()\n",
    "    worker_info = f\"Worker address: {worker.address}, Worker ID: {worker.id}\"\n",
    "    \n",
    "    print(\"dir_list:\", dir_list)\n",
    "    return f\"dir_list: {dir_list}; worker address: {worker.address}, worker ID: {worker.id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b7612b6-6f4e-4e32-a4de-c27e0415ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_list: ['202001']; worker address: tls://10.0.41.42:33547, worker ID: Worker-a6b88bd9-2afa-4655-874e-a4e9792b352e\n",
      "dir_list: ['202002']; worker address: tls://10.0.32.171:34771, worker ID: Worker-d04967d8-c624-4562-92c8-f6d077e0c361\n"
     ]
    }
   ],
   "source": [
    "future_test1 = client.submit(process_data1, [\"202001\"])\n",
    "future_test2 = client.submit(process_data1, [\"202002\"])\n",
    "result1 = future_test1.result()\n",
    "result2 = future_test2.result()\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3ea63ce-03cf-4004-95aa-2ebf50d1d3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ['202001'] at Worker address: tls://10.0.41.42:33547, Worker ID: Worker-a6b88bd9-2afa-4655-874e-a4e9792b352e\n",
      "Processed ['202002'] at Worker address: tls://10.0.32.171:34771, Worker ID: Worker-d04967d8-c624-4562-92c8-f6d077e0c361\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import wait\n",
    "\n",
    "future1 = client.submit(process_data, [\"202001\"])\n",
    "future2 = client.submit(process_data, [\"202002\"])\n",
    "\n",
    "# Wait for tasks to complete\n",
    "wait([future1, future2])\n",
    "\n",
    "# Check results (if tasks completed)\n",
    "if future1.status == \"finished\" and future2.status == \"finished\":\n",
    "    result1 = future1.result()\n",
    "    result2 = future2.result()\n",
    "    print(result1)\n",
    "    print(result2)\n",
    "else:\n",
    "    print(\"One or both tasks were canceled or failed.\")\n",
    "    print(\"Future1 status:\", future1.status)\n",
    "    print(\"Future2 status:\", future2.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d76abf7-6d83-4597-9632-92cade7b4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0c08f-da9f-48f8-b0f5-ff9cde4e5211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stare",
   "language": "python",
   "name": "stare"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
